{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will create a custom CNN model for the CIFAR10 data set.\n",
    "\n",
    "Helpful references:\n",
    "\n",
    "https://www.youtube.com/watch?reload=9&v=eBbEDRsCmv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two functions that will be reused in your custom model function.\n",
    "\n",
    "_conv: convolution block to include conv, relu, and max pool.\n",
    "\n",
    "_dense: dense block with relu.  Since last layer is logits, make relu switchable on/off.\n",
    "\n",
    "(optional) for both blocks, report histogram for W, b, and activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Block\n",
    "\n",
    "def _conv(x,kernel,name,log=False):\n",
    "    with tf.variable_scope(name):\n",
    "        #\n",
    "        # code here\n",
    "        #\n",
    "        if log==True:\n",
    "            #\n",
    "            # code here\n",
    "            #\n",
    "        return # code here\n",
    "\n",
    "# Dense Block\n",
    "\n",
    "def _dense(x,size_in,size_out,name,relu=False,log=False):\n",
    "    with tf.variable_scope(name):\n",
    "        #\n",
    "        # code here\n",
    "        #\n",
    "        if relu==True:\n",
    "            #\n",
    "            # code here\n",
    "            #\n",
    "        if log==True:\n",
    "            #\n",
    "            # code here\n",
    "            #\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create custom model function.\n",
    "\n",
    "INFERENCE MODEL\n",
    "\n",
    "Recommended architecture:\n",
    "- conv1:   kernel = 5x5x128\n",
    "- conv2:   kernel = 5x5x128\n",
    "- conv3:   kernel = 3x3x256\n",
    "- conv4:   kernel = 3x3x512\n",
    "- dense:   hidden_units (tunable hyperparam)\n",
    "- dropout: only for training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnmodel_fn(features, labels, mode, params):\n",
    "    \n",
    "    #### 1 INFERNCE MODEL\n",
    "    \n",
    "        #\n",
    "        # code here\n",
    "        #\n",
    "    if mode==tf.estimator.ModeKeys.TRAIN:\n",
    "        #\n",
    "        # code here for dropout\n",
    "        #\n",
    "    logits = # code here\n",
    " \n",
    "    #### 2 CALCULATIONS AND METRICS\n",
    "    \n",
    "    predictions = {\n",
    "        # code here\n",
    "    }\n",
    "    export_outputs = {'predictions': # code here}\n",
    "    if (mode==tf.estimator.ModeKeys.TRAIN or mode==tf.estimator.ModeKeys.EVAL):\n",
    "        loss = # code here\n",
    "        accuracy = tf.metrics.accuracy(# code here)\n",
    "        metrics = {'accuracy':accuracy}\n",
    "        \n",
    "    #### 3 MODE = PREDICT\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(# code here)\n",
    "\n",
    "    #### 4 MODE = TRAIN\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = tf.train.exponential_decay(# code here)\n",
    "        optimizer = # code here\n",
    "        train_op = # code here\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        tf.summary.scalar('accuracy',accuracy[1])\n",
    "        return tf.estimator.EstimatorSpec(# code here)\n",
    "    \n",
    "    #### 5 MODE = EVAL\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(# code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function to deserialize tfrecords files.\n",
    "\n",
    "Feature dictionary {idx, label, image}\n",
    "\n",
    "- idx:   tf.int64\n",
    "- label: tf.int64\n",
    "- image: tf.string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example):\n",
    "    #\n",
    "    # code here\n",
    "    #\n",
    "    return # code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two helper functions:\n",
    "\n",
    "image_scaling - applied always\n",
    "\n",
    "distort - applied only in training.  Resize, crop, flip randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_scaling(x):\n",
    "    return # code here\n",
    "\n",
    "def distort(x):\n",
    "    #\n",
    "    # code here\n",
    "    #\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input function using tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_input_fn(params):\n",
    "    #\n",
    "    # code here\n",
    "    #\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params  = {'drop_out'      : 0.2,\n",
    "                 'dense_units'   : 1024,\n",
    "                 'learning_rate' : 1e-3,\n",
    "                 'log'           : True\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.estimator.RunConfig(save_checkpoints_secs = 300,keep_checkpoint_max = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set model_fn\n",
    "model_fn = cnnmodel_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'cnn_model/cnn_model_'\n",
    "name = name + 'dense' + str(model_params['dense_units']) + '_'\n",
    "name = name + 'drop' + str(model_params['drop_out']) + '_'\n",
    "name = name + 'lr' + str(model_params['learning_rate']) + '_'\n",
    "name = name + time.strftime(\"%Y%m%d%H%M%S\")\n",
    "model_dir  = os.path.join('./',name)\n",
    "\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,model_dir=model_dir,params=model_params,config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = !ls cifar10_data_00*.tfrecords\n",
    "val_files   = !ls cifar10_data_01*.tfrecords\n",
    "\n",
    "train_params = {'filenames'    : train_files,\n",
    "                'mode'         : tf.estimator.ModeKeys.TRAIN,\n",
    "                'threads'      : 16,\n",
    "                'shuffle_buff' : 100000,\n",
    "                'batch'        : 100\n",
    "               }\n",
    "\n",
    "eval_params  = {'filenames'    : val_files,\n",
    "                'mode'         : tf.estimator.ModeKeys.EVAL,\n",
    "                'threads'      : 8,\n",
    "                'batch'        : 200\n",
    "               }\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=lambda: dataset_input_fn(train_params),max_steps=20000)\n",
    "eval_spec  = tf.estimator.EvalSpec(input_fn=lambda: dataset_input_fn(eval_params),steps=10,throttle_secs=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
