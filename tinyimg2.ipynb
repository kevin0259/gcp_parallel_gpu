{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Block\n",
    "\n",
    "def _conv(x,kernel,name,log=False):\n",
    "    with tf.variable_scope(name):\n",
    "        W = tf.get_variable(initializer=tf.truncated_normal(shape=kernel,stddev=0.01),name='W')\n",
    "        b = tf.get_variable(initializer=tf.constant(0.0,shape=[kernel[3]]),name='b')\n",
    "        conv = tf.nn.conv2d(x, W, strides=[1,1,1,1],padding='SAME')\n",
    "        activation = tf.nn.relu(tf.add(conv,b))\n",
    "        pool = tf.nn.max_pool(activation,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        if log==True:\n",
    "            tf.summary.histogram(\"weights\",W)\n",
    "            tf.summary.histogram(\"biases\",b)\n",
    "            tf.summary.histogram(\"activations\",activation)\n",
    "        return pool\n",
    "\n",
    "# Dense Block\n",
    "\n",
    "def _dense(x,size_in,size_out,name,relu=False,log=False):\n",
    "    with tf.variable_scope(name):\n",
    "        flat = tf.reshape(x,[-1,size_in])\n",
    "        W = tf.get_variable(initializer=tf.truncated_normal([size_in,size_out],stddev=0.1),name='W')\n",
    "        b = tf.get_variable(initializer=tf.constant(0.0,shape=[size_out]),name='b')\n",
    "        activation = tf.add(tf.matmul(flat,W),b)\n",
    "        if relu==True:\n",
    "            activation = tf.nn.relu(activation)\n",
    "        if log==True:\n",
    "            tf.summary.histogram(\"weights\",W)\n",
    "            tf.summary.histogram(\"biases\",b)\n",
    "            tf.summary.histogram(\"activations\",activation)\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tinyimg_fn(features, labels, mode, params):\n",
    "    \n",
    "    #### 1 INFERNCE MODEL\n",
    "    \n",
    "    input_layer = tf.reshape(features, [-1, 64, 64, 3])\n",
    "    conv1 = _conv(input_layer,kernel=[7,7,3,128],name='conv1',log=params['log'])\n",
    "    conv2 = _conv(conv1,kernel=[5,5,128,128],name='conv2',log=params['log'])\n",
    "    conv3 = _conv(conv2,kernel=[5,5,128,256],name='conv3',log=params['log'])\n",
    "    conv4 = _conv(conv3,kernel=[3,3,256,512],name='conv4',log=params['log'])\n",
    "    dense = _dense(conv4,size_in=4*4*512,size_out=params['dense_units'],\n",
    "                   name='Dense',relu=True,log=params['log'])\n",
    "    if mode==tf.estimator.ModeKeys.TRAIN:\n",
    "        dense = tf.nn.dropout(dense,params['drop_out'])\n",
    "    logits = _dense(dense,size_in=params['dense_units'],\n",
    "                    size_out=200,name='Output',relu=False,log=params['log'])\n",
    "    \n",
    "    #### 2 CALCULATIONS AND METRICS\n",
    "    \n",
    "    predictions = {\"classes\": tf.argmax(input=logits,axis=1),\n",
    "                   \"logits\": logits,\n",
    "                   \"probabilities\": tf.nn.softmax(logits,name='softmax')}\n",
    "    export_outputs = {'predictions': tf.estimator.export.PredictOutput(predictions)}\n",
    "    if (mode==tf.estimator.ModeKeys.TRAIN or mode==tf.estimator.ModeKeys.EVAL):\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "        #accuracy = tf.metrics.accuracy(\n",
    "        #    labels=labels, predictions=tf.argmax(logits,axis=1))\n",
    "        #metrics = {'accuracy':accuracy}\n",
    "        \n",
    "    #### 3 MODE = PREDICT\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, predictions=predictions, export_outputs=export_outputs)\n",
    "\n",
    "    #### 4 MODE = TRAIN\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            params['learning_rate'],tf.train.get_global_step(),\n",
    "            decay_steps=100000,decay_rate=0.96)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        if params['replicate']==True:\n",
    "            optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        #tf.summary.scalar('accuracy',accuracy[1])\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    #### 5 MODE = EVAL\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            #mode=mode,loss=loss,eval_metric_ops=metrics)\n",
    "            mode=mode,loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example):\n",
    "    feature={'idx'     : tf.FixedLenFeature((), tf.int64),\n",
    "             'label'   : tf.FixedLenFeature((), tf.int64),\n",
    "             'image'   : tf.FixedLenFeature((), tf.string, default_value='')}\n",
    "    parsed = tf.parse_single_example(example, feature)\n",
    "    image = tf.decode_raw(parsed['image'],tf.float32)\n",
    "    image = tf.reshape(image,[64,64,3])\n",
    "    return image, parsed['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_scaling(x):\n",
    "    return tf.image.per_image_standardization(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distort(x):\n",
    "    x = tf.image.resize_image_with_crop_or_pad(x, 80, 80)\n",
    "    x = tf.random_crop(x, [64, 64, 3])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_input_fn(params):\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        params['filenames'],num_parallel_reads=params['threads'])\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=params['threads'])\n",
    "    dataset = dataset.map(\n",
    "    lambda x,y: (image_scaling(x),y),num_parallel_calls=params['threads'])\n",
    "    if params['mode']==tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.map(lambda x,y: (distort(x),y),num_parallel_calls=params['threads'])\n",
    "        dataset = dataset.shuffle(buffer_size=params['shuffle_buff'])\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(params['batch'])\n",
    "    dataset = dataset.prefetch(2*params['batch'])\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconfig = tf.estimator.RunConfig(save_checkpoints_secs = 30,keep_checkpoint_max = 5)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params  = {'drop_out'      : 0.3,\n",
    "                 'dense_units'   : 1024,\n",
    "                 'learning_rate' : 1e-3,\n",
    "                 'log'           : True,\n",
    "                 'replicate'     : False\n",
    "                }\n",
    "\n",
    "distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=8)\n",
    "config = tf.estimator.RunConfig(save_checkpoints_secs = 30,\n",
    "                                keep_checkpoint_max = 5,\n",
    "                                session_config=tf.ConfigProto(\n",
    "                                    allow_soft_placement=True, log_device_placement=True),\n",
    "                                train_distribute = distribution)\n",
    "'''\n",
    "config = tf.estimator.RunConfig(save_checkpoints_secs = 30,keep_checkpoint_max = 5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tsaikevin/zzz/tinyimagenet/tiny-imagenet-200\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_log_step_count_steps': 100, '_model_dir': './cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541', '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f47291107f0>, '_global_id_in_cluster': 0, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4729110860>, '_num_ps_replicas': 0, '_tf_random_seed': None, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_secs': 30, '_save_checkpoints_steps': None, '_session_config': allow_soft_placement: true\n",
      "log_device_placement: true\n",
      ", '_num_worker_replicas': 1, '_service': None, '_keep_checkpoint_max': 5, '_master': '', '_evaluation_master': ''}\n"
     ]
    }
   ],
   "source": [
    "if model_params['replicate']==True:\n",
    "    model_fn = tf.contrib.estimator.replicate_model_fn(\n",
    "        tinyimg_fn, loss_reduction=tf.losses.Reduction.MEAN)\n",
    "else:\n",
    "    model_fn = tinyimg_fn\n",
    "\n",
    "name = 'cnn_model/cnn_model_'\n",
    "if model_params['replicate']==True:\n",
    "    name = 'cnn_model_dist/cnn_model_'\n",
    "name = name + 'dense(' + str(model_params['dense_units']) + ')_'\n",
    "name = name + 'drop(' + str(model_params['drop_out']) + ')_'\n",
    "name = name + 'lr(' + str(model_params['learning_rate']) + ')_'\n",
    "name = name + time.strftime(\"%Y%m%d%H%M%S\")\n",
    "cnn_dir  = os.path.join('./',name)\n",
    "\n",
    "print(cnn_dir)\n",
    "\n",
    "cnn_classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,model_dir=cnn_dir,params=model_params,config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_log_step_count_steps': 100, '_model_dir': './cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541', '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f46865567f0>, '_global_id_in_cluster': 0, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4686556e10>, '_num_ps_replicas': 0, '_tf_random_seed': None, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_secs': 30, '_save_checkpoints_steps': None, '_session_config': allow_soft_placement: true\n",
      "log_device_placement: true\n",
      ", '_num_worker_replicas': 1, '_service': None, '_keep_checkpoint_max': 5, '_master': '', '_evaluation_master': ''}\n"
     ]
    }
   ],
   "source": [
    "tinyimg_estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,model_dir=cnn_dir,params=model_params,config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_files = !gsutil ls gs://tsaikevin-data/tiny_imagenet/tiny_imagenet_00*.tfrecords\n",
    "#val_files   = !gsutil ls gs://tsaikevin-data/tiny_imagenet/tiny_imagenet_01*.tfrecords\n",
    "train_files = !ls tiny_imagenet_2_00*.tfrecords\n",
    "val_files   = !ls tiny_imagenet_2_01*.tfrecords\n",
    "\n",
    "train_params = {'filenames'    : train_files,\n",
    "                'mode'         : tf.estimator.ModeKeys.TRAIN,\n",
    "                'threads'      : 16,\n",
    "                'shuffle_buff' : 100000,\n",
    "                'batch'        : 100\n",
    "               }\n",
    "\n",
    "eval_params  = {'filenames'    : val_files,\n",
    "                'mode'         : tf.estimator.ModeKeys.EVAL,\n",
    "                'threads'      : 8,\n",
    "                'batch'        : 200\n",
    "               }\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=lambda: dataset_input_fn(train_params),max_steps=2000)\n",
    "eval_spec  = tf.estimator.EvalSpec(input_fn=lambda: dataset_input_fn(eval_params),steps=10,throttle_secs=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: The rm command (without -I) expects at least one URL.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\n",
      "INFO:tensorflow:Configured nccl all-reduce.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 12 with algorithm = nccl and num_packs = 1\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.301813, step = 0\n",
      "INFO:tensorflow:global_step/sec: 4.42835\n",
      "INFO:tensorflow:loss = 5.3109965, step = 100 (22.584 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 112 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.49725\n",
      "INFO:tensorflow:loss = 5.2982793, step = 200 (28.594 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 224 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.56058\n",
      "INFO:tensorflow:loss = 5.29909, step = 300 (28.085 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 335 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.33739\n",
      "INFO:tensorflow:loss = 5.2903414, step = 400 (29.964 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 447 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.31413\n",
      "INFO:tensorflow:loss = 5.2922387, step = 500 (30.173 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 558 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.31969\n",
      "INFO:tensorflow:loss = 5.2891183, step = 600 (30.124 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 670 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.30122\n",
      "INFO:tensorflow:loss = 5.293341, step = 700 (30.292 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 781 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.31521\n",
      "INFO:tensorflow:loss = 5.290425, step = 800 (30.164 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 893 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.31755\n",
      "INFO:tensorflow:loss = 5.2898755, step = 900 (30.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.71141\n",
      "INFO:tensorflow:loss = 5.292268, step = 1000 (21.225 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1005 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.49675\n",
      "INFO:tensorflow:loss = 5.283537, step = 1100 (28.598 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1116 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.55129\n",
      "INFO:tensorflow:loss = 5.2830086, step = 1200 (28.159 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1228 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.32546\n",
      "INFO:tensorflow:loss = 5.2851014, step = 1300 (30.071 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1339 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.31951\n",
      "INFO:tensorflow:loss = 5.281635, step = 1400 (30.125 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1451 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.30165\n",
      "INFO:tensorflow:loss = 5.281754, step = 1500 (30.288 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1562 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.30971\n",
      "INFO:tensorflow:loss = 5.2854013, step = 1600 (30.214 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1674 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.31604\n",
      "INFO:tensorflow:loss = 5.273518, step = 1700 (30.157 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1785 into ./cnn_model/cnn_model_dense(1024)_drop(0.3)_lr(0.001)_20180527020541/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.3073\n",
      "INFO:tensorflow:loss = 5.271528, step = 1800 (30.236 sec)\n"
     ]
    }
   ],
   "source": [
    "!gsutil rm -rf $model_dir\n",
    "tf.estimator.train_and_evaluate(tinyimg_estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'tiny_imagenet_00*.tfrecords': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls tiny_imagenet_00*.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_model\t\t\t      tiny_imagenet_2_007.tfrecords\r\n",
      "cnn_model_dist\t\t\t      tiny_imagenet_2_008.tfrecords\r\n",
      "create_tfrecords.ipynb\t\t      tiny_imagenet_2_009.tfrecords\r\n",
      "model.py\t\t\t      tiny_imagenet_2_010.tfrecords\r\n",
      "__pycache__\t\t\t      tiny_imagenet_2_011.tfrecords\r\n",
      "resnet_v2\t\t\t      tinyimg2.ipynb\r\n",
      "resnet_v2_imagenet_savedmodel.tar.gz  tinyimg-distributed.ipynb\r\n",
      "test\t\t\t\t      tinyimg.ipynb\r\n",
      "tiny_imagenet_2_000.tfrecords\t      tinyimg-tf18-distributed.ipynb\r\n",
      "tiny_imagenet_2_001.tfrecords\t      tinyimg-tf18.ipynb\r\n",
      "tiny_imagenet_2_002.tfrecords\t      train\r\n",
      "tiny_imagenet_2_003.tfrecords\t      val\r\n",
      "tiny_imagenet_2_004.tfrecords\t      wnids.txt\r\n",
      "tiny_imagenet_2_005.tfrecords\t      words.txt\r\n",
      "tiny_imagenet_2_006.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
