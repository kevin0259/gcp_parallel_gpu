{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline with tf.estimator\n",
    "\n",
    "<img src=\"img/tf_estimator_diagram.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premade Estimator\n",
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Input Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},y=train_labels,batch_size=100,num_epochs=None,shuffle=True)\n",
    "eval_input_fn  = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},y=eval_labels,num_epochs=1,shuffle=False)\n",
    "pred_input_fn  = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},num_epochs=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Set paramters and model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config     = tf.estimator.RunConfig(save_checkpoints_secs = 30, keep_checkpoint_max = 5)\n",
    "\n",
    "#mnist_path = 'gs://tsaikevin-working/models/mnist/'\n",
    "mnist_path = './mnist/'\n",
    "dnn_dir = mnist_path + 'dnn_model/dnn_model'\n",
    "dnn_dir = dnn_dir + '_' + time.strftime(\"%Y%m%d%H%M%S\")\n",
    "dnn_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNNClassifier requires feature in a list\n",
    "features = [tf.feature_column.numeric_column(\"x\",shape=([784]),dtype=tf.float32)]\n",
    "\n",
    "dnn_classifier = tf.estimator.DNNClassifier(hidden_units=[64,64],feature_columns=features,\n",
    "                                            model_dir=dnn_dir,n_classes=10,config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create TrainSpec and EvalSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=10000)\n",
    "eval_spec  = tf.estimator.EvalSpec(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $dnn_dir\n",
    "tf.estimator.train_and_evaluate(dnn_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Contents of model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l $dnn_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rerun same train_and_evaluate command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(dnn_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rerun command with higher max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=20000)\n",
    "tf.estimator.train_and_evaluate(dnn_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l $dnn_dir\n",
    "!cat $dnn_dir/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(dnn_classifier.predict(input_fn=pred_input_fn))\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    receiver_tensor = {'x': tf.placeholder(shape=[None,28,28,1], dtype=tf.string)}\n",
    "    features = {'x': receiver_tensor['x']}\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)\n",
    "\n",
    "dnn_classifier.export_savedmodel(\n",
    "    export_dir_base=dnn_dir,serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Custom Estimator\n",
    "## 3. Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Block\n",
    "\n",
    "def _conv(x,kernel,name,log=False):\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.Variable(tf.truncated_normal(shape=kernel,stddev=0.01),name='W')\n",
    "        b = tf.Variable(tf.constant(0.0,shape=[kernel[3]]),name='b')\n",
    "        conv = tf.nn.conv2d(x, W, strides=[1,1,1,1],padding='SAME')\n",
    "        activation = tf.nn.relu(tf.add(conv,b))\n",
    "        pool = tf.nn.max_pool(activation,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        if log==True:\n",
    "            tf.summary.histogram(\"weights\",W)\n",
    "            tf.summary.histogram(\"biases\",b)\n",
    "            tf.summary.histogram(\"activations\",activation)\n",
    "        return pool\n",
    "\n",
    "# Dense Block\n",
    "\n",
    "def _dense(x,size_in,size_out,name,relu=False,log=False):\n",
    "    with tf.name_scope(name):\n",
    "        flat = tf.reshape(x,[-1,size_in])\n",
    "        W = tf.Variable(tf.truncated_normal([size_in,size_out],stddev=0.1),name='W')\n",
    "        b = tf.Variable(tf.constant(0.0,shape=[size_out]),name='b')\n",
    "        activation = tf.add(tf.matmul(flat,W),b)\n",
    "        if relu==True:\n",
    "            activation = tf.nn.relu(activation)\n",
    "        if log==True:\n",
    "            tf.summary.histogram(\"weights\",W)\n",
    "            tf.summary.histogram(\"biases\",b)\n",
    "            tf.summary.histogram(\"activations\",activation)\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, params):\n",
    "    \n",
    "    #### 1 INFERNCE MODEL\n",
    "    \n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "    conv1 = _conv(input_layer,kernel=[5,5,1,64],name='conv1',log=params['log'])\n",
    "    conv2 = _conv(conv1,kernel=[5,5,64,64],name='conv2',log=params['log'])\n",
    "    dense = _dense(conv2,size_in=7*7*64,size_out=params['dense_units'],\n",
    "                   name='Dense',relu=True,log=params['log'])\n",
    "    if mode==tf.estimator.ModeKeys.TRAIN:\n",
    "        dense = tf.nn.dropout(dense,params['drop_out'])\n",
    "    logits = _dense(dense,size_in=params['dense_units'],\n",
    "                    size_out=10,name='Output',relu=False,log=params['log'])\n",
    "    \n",
    "    #### 2 CALCULATIONS AND METRICS\n",
    "    \n",
    "    predictions = {\"classes\": tf.argmax(input=logits,axis=1),\n",
    "                   \"logits\": logits,\n",
    "                   \"probabilities\": tf.nn.softmax(logits,name='softmax')}\n",
    "    export_outputs = {'predictions': tf.estimator.export.PredictOutput(predictions)}\n",
    "    if (mode==tf.estimator.ModeKeys.TRAIN or mode==tf.estimator.ModeKeys.EVAL):\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "        accuracy = tf.metrics.accuracy(\n",
    "            labels=labels, predictions=tf.argmax(logits,axis=1))\n",
    "        metrics = {'accuracy':accuracy}\n",
    "        \n",
    "    #### 3 MODE = PREDICT\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, predictions=predictions, export_outputs=export_outputs)\n",
    "\n",
    "    #### 4 MODE = TRAIN\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            params['learning_rate'],tf.train.get_global_step(),\n",
    "            decay_steps=100000,decay_rate=0.96)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        if params['replicate']==True:\n",
    "            optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        tf.summary.scalar('accuracy',accuracy[1])\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    #### 5 MODE = EVAL\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,loss=loss,eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Set paramters and model pathÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config     = tf.estimator.RunConfig(save_checkpoints_secs = 30, keep_checkpoint_max = 5)\n",
    "\n",
    "#mnist_path = 'gs://tsaikevin-working/models/mnist/'\n",
    "mnist_path = './mnist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params  = {'drop_out'      : 0.8,\n",
    "                 'dense_units'   : 1024,\n",
    "                 'learning_rate' : 1e-3,\n",
    "                 'log'           : True,\n",
    "                 'replicate'     : False\n",
    "                }\n",
    "\n",
    "name = 'cnn_model_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_params['replicate']==True:\n",
    "    cnn_model_fn = tf.contrib.estimator.replicate_model_fn(\n",
    "        cnn_model_fn, loss_reduction=tf.losses.Reduction.MEAN)\n",
    "\n",
    "name = 'cnn_model/cnn_model_'\n",
    "if model_params['replicate']==True:\n",
    "    name = 'cnn_model_dist/cnn_model_'\n",
    "name = name + 'dense(' + str(model_params['dense_units']) + ')_'\n",
    "name = name + 'drop(' + str(model_params['drop_out']) + ')_'\n",
    "name = name + 'lr(' + str(model_params['learning_rate']) + ')_'\n",
    "name = name + time.strftime(\"%Y%m%d%H%M%S\")\n",
    "cnn_dir  = os.path.join(mnist_path,name)\n",
    "\n",
    "print(cnn_dir)\n",
    "\n",
    "cnn_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,model_dir=cnn_dir,params=model_params,config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create TrainSpec and EvalSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=20000)\n",
    "eval_spec  = tf.estimator.EvalSpec(input_fn=eval_input_fn,throttle_secs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(cnn_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(cnn_classifier.predict(input_fn=pred_input_fn))\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    receiver_tensor = {'x': tf.placeholder(shape=[None,28,28,1], dtype=tf.float32)}\n",
    "    features = {'x': receiver_tensor['x']}\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)\n",
    "\n",
    "cnn_classifier.export_savedmodel(\n",
    "    export_dir_base=cnn_dir,serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
