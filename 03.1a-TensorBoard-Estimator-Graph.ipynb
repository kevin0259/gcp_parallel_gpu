{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard Session Lab: tf.estimator\n",
    "\n",
    "In this lab, you will visualize the TF graph for a tf.estimator model\n",
    "\n",
    "Helpful references:\n",
    "- https://www.youtube.com/watch?reload=9&v=eBbEDRsCmv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two functions that will be reused in your custom model function.\n",
    "\n",
    "_conv:\n",
    "- Convolution block to include conv, relu, and max pool.\n",
    "- Use tf.variable_scope.\n",
    "- Input should include feature, kernel (convolution filter), variable scope name\n",
    "\n",
    "_dense:\n",
    "- Dense block with relu.  Since last layer is logits, make relu switchable on/off.\n",
    "- Use tf.variable_scope.\n",
    "- Since last layer is logits, make relu switchable on/off.\n",
    "- Input should include feature, in/out sizes, variable scope name, relu(true/false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Block\n",
    "\n",
    "def _conv(x,kernel,name,log=False):\n",
    "    with tf.variable_scope(name):\n",
    "        W = tf.get_variable(initializer=tf.truncated_normal(shape=kernel,stddev=0.01),name='W')\n",
    "        b = tf.get_variable(initializer=tf.constant(0.0,shape=[kernel[3]]),name='b')\n",
    "        conv = tf.nn.conv2d(x, W, strides=[1,1,1,1],padding='SAME')\n",
    "        activation = tf.nn.relu(tf.add(conv,b))\n",
    "        pool = tf.nn.max_pool(activation,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        #if log==True:\n",
    "            #\n",
    "            # code here\n",
    "            #\n",
    "        return pool\n",
    "\n",
    "# Dense Block\n",
    "\n",
    "def _dense(x,size_in,size_out,name,relu=False,log=False):\n",
    "    with tf.variable_scope(name):\n",
    "        flat = tf.reshape(x,[-1,size_in])\n",
    "        W = tf.get_variable(initializer=tf.truncated_normal([size_in,size_out],stddev=0.1),name='W')\n",
    "        b = tf.get_variable(initializer=tf.constant(0.0,shape=[size_out]),name='b')\n",
    "        activation = tf.add(tf.matmul(flat,W),b)\n",
    "        if relu==True:\n",
    "            activation = tf.nn.relu(activation)\n",
    "        #if log==True:\n",
    "            #\n",
    "            # code here\n",
    "            #\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model function.\n",
    "\n",
    "5 sections of the model function\n",
    "\n",
    "#### 1. INFERENCE MODEL\n",
    "\n",
    "Recommended architecture:\n",
    "- conv1: kernel = 5x5x128\n",
    "- conv2: kernel = 5x5x128\n",
    "- conv3: kernel = 3x3x256\n",
    "- conv4: kernel = 3x3x512\n",
    "- dense: hidden_units (tunable hyperparam)\n",
    "\n",
    "Use:\n",
    "- tf.nn - this will allow for metric collection later.\n",
    "\n",
    "#### 2. CALCULATIONS AND METRICS\n",
    "\n",
    "Implement:\n",
    "- Prediction dictionary {classes, logits, probabilities}.\n",
    "- Loss function: Cross Entropy.\n",
    "- Accuracy for both training and eval using tf.metrics.\n",
    "\n",
    "#### 3. MODE = PREDICT\n",
    "\n",
    "Implement:\n",
    "- EstimatorSpec for PREDICT.\n",
    "\n",
    "#### 4. MODE = TRAIN\n",
    "\n",
    "Implement:\n",
    "- Optimizer = Stochastic Gradient Descent.\n",
    "- EstimatorSpec for TRAIN.\n",
    "- Optional: Exponential Decay Learning Rate.\n",
    "\n",
    "#### 5. MODE = EVAL\n",
    "\n",
    "Implement:\n",
    "- EstimatorSpec for EVAL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a - Graph with bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnmodel_fn(features, labels, mode, params):\n",
    "    \n",
    "    #### 1 INFERNCE MODEL\n",
    "\n",
    "   \n",
    "    input_layer = tf.reshape(features, [-1, 32, 32, 3])\n",
    "    conv1 = _conv(input_layer,kernel=[5,5,3,128],name='conv1',log=params['log'])\n",
    "    conv2 = _conv(conv1,kernel=[5,5,128,128],name='conv2',log=params['log'])\n",
    "    conv3 = _conv(conv2,kernel=[3,3,128,256],name='conv3',log=params['log'])\n",
    "    conv4 = _conv(conv2,kernel=[5,5,128,256],name='conv4',log=params['log'])\n",
    "    dense = _dense(conv2,size_in=2*2*2048,size_out=params['dense_units'],\n",
    "                   name='Dense',relu=True,log=params['log'])\n",
    "    if mode==tf.estimator.ModeKeys.TRAIN:\n",
    "        dense = tf.nn.dropout(dense,params['drop_out'])\n",
    "    logits = _dense(dense,size_in=params['dense_units'],\n",
    "                    size_out=10,name='Output',relu=False,log=params['log'])\n",
    "        \n",
    "    #### 2 CALCULATIONS AND METRICS\n",
    "    \n",
    "    predictions = {\"classes\": tf.argmax(input=logits,axis=1),\n",
    "                   \"logits\": logits,\n",
    "                   \"probabilities\": tf.nn.softmax(logits,name='softmax')}\n",
    "    export_outputs = {'predictions': tf.estimator.export.PredictOutput(predictions)}\n",
    "    if (mode==tf.estimator.ModeKeys.TRAIN or mode==tf.estimator.ModeKeys.EVAL):\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "        accuracy = tf.metrics.accuracy(\n",
    "            labels=labels, predictions=tf.argmax(logits,axis=1))\n",
    "        metrics = {'accuracy':accuracy}\n",
    "        \n",
    "    #### 3 MODE = PREDICT\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, predictions=predictions, export_outputs=export_outputs)\n",
    "\n",
    "    #### 4 MODE = TRAIN\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            params['learning_rate'],tf.train.get_global_step(),\n",
    "            decay_steps=100000,decay_rate=0.96)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    #### 5 MODE = EVAL\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,loss=loss,eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP DO NOT RUN SECTION 1b\n",
    "## 1b - Fixed Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnmodel_fn(features, labels, mode, params):\n",
    "    \n",
    "    #### 1 INFERNCE MODEL\n",
    "    \n",
    "    input_layer = tf.reshape(features, [-1, 32, 32, 3])\n",
    "    conv1 = _conv(input_layer,kernel=[5,5,3,128],name='conv1',log=params['log'])\n",
    "    conv2 = _conv(conv1,kernel=[5,5,128,128],name='conv2',log=params['log'])\n",
    "    conv3 = _conv(conv2,kernel=[3,3,128,256],name='conv3',log=params['log'])\n",
    "    conv4 = _conv(conv3,kernel=[3,3,256,512],name='conv4',log=params['log'])\n",
    "    dense = _dense(conv4,size_in=2*2*512,size_out=params['dense_units'],\n",
    "                   name='Dense',relu=True,log=params['log'])\n",
    "    if mode==tf.estimator.ModeKeys.TRAIN:\n",
    "        dense = tf.nn.dropout(dense,params['drop_out'])\n",
    "    logits = _dense(dense,size_in=params['dense_units'],\n",
    "                    size_out=10,name='Output',relu=False,log=params['log'])\n",
    "        \n",
    "    #### 2 CALCULATIONS AND METRICS\n",
    "    \n",
    "    predictions = {\"classes\": tf.argmax(input=logits,axis=1),\n",
    "                   \"logits\": logits,\n",
    "                   \"probabilities\": tf.nn.softmax(logits,name='softmax')}\n",
    "    export_outputs = {'predictions': tf.estimator.export.PredictOutput(predictions)}\n",
    "    if (mode==tf.estimator.ModeKeys.TRAIN or mode==tf.estimator.ModeKeys.EVAL):\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "        accuracy = tf.metrics.accuracy(\n",
    "            labels=labels, predictions=tf.argmax(logits,axis=1))\n",
    "        metrics = {'accuracy':accuracy}\n",
    "        \n",
    "    #### 3 MODE = PREDICT\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, predictions=predictions, export_outputs=export_outputs)\n",
    "\n",
    "    #### 4 MODE = TRAIN\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            params['learning_rate'],tf.train.get_global_step(),\n",
    "            decay_steps=100000,decay_rate=0.96)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "        #\n",
    "        # \n",
    "        #\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    #### 5 MODE = EVAL\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,loss=loss,eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a - Function to deserialize tfrecords files.\n",
    "\n",
    "Implement parse_tfrecord function:\n",
    "- Feature input: {idx: tf.int64, label: tf.int64, image: tf.string}\n",
    "- Return: image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example):\n",
    "    feature={'idx'     : tf.FixedLenFeature((), tf.int64),\n",
    "             'label'   : tf.FixedLenFeature((), tf.int64),\n",
    "             'image'   : tf.FixedLenFeature((), tf.string, default_value=\"\")}\n",
    "    parsed = tf.parse_single_example(example, feature)\n",
    "    image = tf.decode_raw(parsed['image'],tf.float64)\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image = tf.reshape(image,[32,32,3])\n",
    "    return image, parsed['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two helper functions:\n",
    "\n",
    "Implement image_scaling function:\n",
    "- Image scaling.\n",
    "- Applied always\n",
    "\n",
    "Implement distort function:\n",
    "- Applied only in training.\n",
    "- Resize, crop, flip randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_scaling(x):\n",
    "    return tf.image.per_image_standardization(x)\n",
    "\n",
    "def distort(x):\n",
    "    x = tf.image.resize_image_with_crop_or_pad(x, 40, 40)\n",
    "    x = tf.random_crop(x, [32, 32, 3])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input function using tf.data\n",
    "\n",
    "Create dataset_input_fn that implements:\n",
    "- Use TFRecordDataset to read tfrecord files.\n",
    "- Apply parse function you created above.\n",
    "- Apply image scaling function you created above.\n",
    "- Apply distort function on for training.\n",
    "- Suffle only for training.\n",
    "- Use prefetch\n",
    "- Optional: parallelize threads wherever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_input_fn(params):\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        params['filenames'],num_parallel_reads=params['threads'])\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=params['threads'])\n",
    "    dataset = dataset.map(lambda x,y: (image_scaling(x),y),num_parallel_calls=params['threads'])\n",
    "    if params['mode']==tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.map(lambda x,y: (distort(x),y),num_parallel_calls=params['threads'])\n",
    "        dataset = dataset.shuffle(buffer_size=params['shuffle_buff'])\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(params['batch'])\n",
    "    dataset = dataset.prefetch(8*params['batch'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO: Logging Switch Parameter\n",
    "\n",
    "Implement logging parameter to turn on/off histogram logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params  = {'drop_out'      : 0.2,\n",
    "                 'dense_units'   : 1024,\n",
    "                 'learning_rate' : 1e-3,\n",
    "                 'log'           : False # change to True\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RunConfig\n",
    "\n",
    "Implement RunConfig:\n",
    "- Save checkpoints ever 300 seconds.\n",
    "- Keep up to 5 checkpoint history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.estimator.RunConfig(save_checkpoints_secs = 300,keep_checkpoint_max = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set model_fn\n",
    "model_fn = cnnmodel_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model directory.  This is to make sorting out runs more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cnn_model/cnn_model_dense1024_drop0.2_lr0.001_20180731220212\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn_model/cnn_model_'\n",
    "name = name + 'dense' + str(model_params['dense_units']) + '_'\n",
    "name = name + 'drop' + str(model_params['drop_out']) + '_'\n",
    "name = name + 'lr' + str(model_params['learning_rate']) + '_'\n",
    "name = name + time.strftime(\"%Y%m%d%H%M%S\")\n",
    "model_dir  = os.path.join('./',name)\n",
    "\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_master': '', '_save_summary_steps': 100, '_device_fn': None, '_train_distribute': None, '_service': None, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_model_dir': './cnn_model/cnn_model_dense1024_drop0.2_lr0.001_20180731220212', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98a198afd0>, '_task_type': 'worker', '_session_config': None, '_task_id': 0, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_tf_random_seed': None, '_save_checkpoints_secs': 300, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,model_dir=model_dir,params=model_params,config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters for input functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = !ls ./data/cifar10_data_00*.tfrecords\n",
    "val_files   = !ls ./data/cifar10_data_01*.tfrecords\n",
    "\n",
    "train_params = {'filenames'    : train_files,\n",
    "                'mode'         : tf.estimator.ModeKeys.TRAIN,\n",
    "                'threads'      : 16,\n",
    "                'shuffle_buff' : 100000,\n",
    "                'batch'        : 100\n",
    "               }\n",
    "\n",
    "eval_params  = {'filenames'    : val_files,\n",
    "                'mode'         : tf.estimator.ModeKeys.EVAL,\n",
    "                'threads'      : 8,\n",
    "                'batch'        : 200\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO: TrainSpec and EvalSpec\n",
    "\n",
    "TranSpec:\n",
    "- Use train_params.\n",
    "- End after 20,000 steps.\n",
    "\n",
    "EvalSpec:\n",
    "- Use eval_params.\n",
    "- 10 steps.\n",
    "- Eval executes every 60 seconds or training time (production will be much longer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(input_fn=lambda: dataset_input_fn(train_params),max_steps=20000)\n",
    "eval_spec  = tf.estimator.EvalSpec(input_fn=lambda: dataset_input_fn(eval_params),steps=10,throttle_secs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 60 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./cnn_model/cnn_model_dense1024_drop0.2_lr0.001_20180731220212/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3025055, step = 0\n",
      "INFO:tensorflow:global_step/sec: 77.224\n",
      "INFO:tensorflow:loss = 2.298281, step = 100 (1.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0255\n",
      "INFO:tensorflow:loss = 2.296463, step = 200 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6519\n",
      "INFO:tensorflow:loss = 2.2979407, step = 300 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.094\n",
      "INFO:tensorflow:loss = 2.2817075, step = 400 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0262\n",
      "INFO:tensorflow:loss = 2.2870352, step = 500 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6003\n",
      "INFO:tensorflow:loss = 2.2822618, step = 600 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6099\n",
      "INFO:tensorflow:loss = 2.2838778, step = 700 (1.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6793\n",
      "INFO:tensorflow:loss = 2.278045, step = 800 (1.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2833\n",
      "INFO:tensorflow:loss = 2.262649, step = 900 (1.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.0962\n",
      "INFO:tensorflow:loss = 2.2072146, step = 1000 (1.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6314\n",
      "INFO:tensorflow:loss = 2.1527107, step = 1100 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5258\n",
      "INFO:tensorflow:loss = 2.210935, step = 1200 (1.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.4829\n",
      "INFO:tensorflow:loss = 2.2125814, step = 1300 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.4531\n",
      "INFO:tensorflow:loss = 2.1891189, step = 1400 (1.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0392\n",
      "INFO:tensorflow:loss = 2.0773613, step = 1500 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6377\n",
      "INFO:tensorflow:loss = 2.0878503, step = 1600 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8434\n",
      "INFO:tensorflow:loss = 2.0500681, step = 1700 (1.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.9322\n",
      "INFO:tensorflow:loss = 2.1039624, step = 1800 (1.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.8793\n",
      "INFO:tensorflow:loss = 2.0476143, step = 1900 (1.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.1253\n",
      "INFO:tensorflow:loss = 2.0433242, step = 2000 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7054\n",
      "INFO:tensorflow:loss = 2.0713615, step = 2100 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5331\n",
      "INFO:tensorflow:loss = 2.0150175, step = 2200 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6494\n",
      "INFO:tensorflow:loss = 2.000247, step = 2300 (1.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6336\n",
      "INFO:tensorflow:loss = 2.0011091, step = 2400 (1.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2125\n",
      "INFO:tensorflow:loss = 2.03862, step = 2500 (1.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7829\n",
      "INFO:tensorflow:loss = 2.1043541, step = 2600 (1.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2377\n",
      "INFO:tensorflow:loss = 1.9206825, step = 2700 (1.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8464\n",
      "INFO:tensorflow:loss = 1.9810158, step = 2800 (1.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5788\n",
      "INFO:tensorflow:loss = 1.8858708, step = 2900 (1.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.7476\n",
      "INFO:tensorflow:loss = 1.9673073, step = 3000 (1.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0996\n",
      "INFO:tensorflow:loss = 1.8873633, step = 3100 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5621\n",
      "INFO:tensorflow:loss = 1.9299446, step = 3200 (1.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7785\n",
      "INFO:tensorflow:loss = 1.940972, step = 3300 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6471\n",
      "INFO:tensorflow:loss = 1.8458406, step = 3400 (1.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5073\n",
      "INFO:tensorflow:loss = 1.8755753, step = 3500 (1.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3386\n",
      "INFO:tensorflow:loss = 1.6973464, step = 3600 (1.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7801\n",
      "INFO:tensorflow:loss = 1.9061245, step = 3700 (1.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6515\n",
      "INFO:tensorflow:loss = 1.8361377, step = 3800 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8629\n",
      "INFO:tensorflow:loss = 1.8963165, step = 3900 (1.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.4518\n",
      "INFO:tensorflow:loss = 1.9405785, step = 4000 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5348\n",
      "INFO:tensorflow:loss = 1.9497894, step = 4100 (1.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0103\n",
      "INFO:tensorflow:loss = 1.8871669, step = 4200 (1.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6579\n",
      "INFO:tensorflow:loss = 1.8660862, step = 4300 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6787\n",
      "INFO:tensorflow:loss = 1.861715, step = 4400 (1.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.624\n",
      "INFO:tensorflow:loss = 1.726319, step = 4500 (1.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.7766\n",
      "INFO:tensorflow:loss = 1.8258014, step = 4600 (1.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3299\n",
      "INFO:tensorflow:loss = 1.7943813, step = 4700 (1.187 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4742 into ./cnn_model/cnn_model_dense1024_drop0.2_lr0.001_20180731220212/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.8239349.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-31-22:03:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/cnn_model_dense1024_drop0.2_lr0.001_20180731220212/model.ckpt-4742\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-31-22:03:17\n",
      "INFO:tensorflow:Saving dict for global step 4742: accuracy = 0.399, global_step = 4742, loss = 1.6699069\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4742: ./cnn_model/cnn_model_dense1024_drop0.2_lr0.001_20180731220212/model.ckpt-4742\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/cnn_model_dense1024_drop0.2_lr0.001_20180731220212/model.ckpt-4742\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4742 into ./cnn_model/cnn_model_dense1024_drop0.2_lr0.001_20180731220212/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.8085763, step = 4742\n",
      "INFO:tensorflow:global_step/sec: 77.3658\n",
      "INFO:tensorflow:loss = 1.8676181, step = 4842 (1.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.9687\n",
      "INFO:tensorflow:loss = 1.8868589, step = 4942 (1.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6088\n",
      "INFO:tensorflow:loss = 1.8180684, step = 5042 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7713\n",
      "INFO:tensorflow:loss = 1.7919883, step = 5142 (1.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0492\n",
      "INFO:tensorflow:loss = 1.7189767, step = 5242 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.9255\n",
      "INFO:tensorflow:loss = 1.8136153, step = 5342 (1.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6573\n",
      "INFO:tensorflow:loss = 1.7949, step = 5442 (1.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5954\n",
      "INFO:tensorflow:loss = 1.9362918, step = 5542 (1.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2342\n",
      "INFO:tensorflow:loss = 1.7017523, step = 5642 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7864\n",
      "INFO:tensorflow:loss = 1.6517907, step = 5742 (1.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7357\n",
      "INFO:tensorflow:loss = 1.8473125, step = 5842 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2637\n",
      "INFO:tensorflow:loss = 1.7990799, step = 5942 (1.187 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-30df9d6a3d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    445\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    530\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m           hooks=train_hooks)\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_continuous_eval_listener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1133\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1134\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1334\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    575\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1051\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1054\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
